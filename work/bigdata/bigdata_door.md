Hbase读写过程

Hbase简单的使用介绍

spark rdd的提交流程

（1）sparkContext向资源管理器注册并申请资源
（2）资源管理器根据预先设定的算法，在资源池里分配合适的Executor运行资源
（3）应用(Main函数里的算子)构建有向无环图
（4）DAGScheduler将图转换成TaskSet
（5）TaskScheduler负责TaskSet的任务分发。

hadoop的基本介绍

hive数据仓库的清洗流程，维度介绍，分层介绍

hadoop的日常工作

